#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIO æ½›åŠ›åˆ†æå™¨ - æ ¸å¿ƒåŠŸèƒ½
========================

æ­¤å·¥å…·ç”¨æ–¼åˆ†æé—œéµå­—è§¸ç™¼ Google AI Overview (AIO) çš„æ½›åŠ›ï¼Œ
é€éæ•´åˆ Google Search Consoleã€Google Ads API å’Œ SERP API
ä¾†æä¾›å…¨é¢çš„ AIO åˆ†æå ±å‘Šã€‚

Author: AIO Analytics Team
Version: 1.0.0
"""

import os
import sys
import asyncio
import aiohttp
import pandas as pd
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from pathlib import Path

# æ·»åŠ  src ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from config.settings import Config
from utils.gsc_handler import GSCHandler
from utils.ads_handler import AdsHandler
from utils.serp_handler import SERPHandler
from utils.report_generator import ReportGenerator
from utils.logger import setup_logger


class AIOAnalyzer:
    """AIO æ½›åŠ›åˆ†æå™¨ä¸»é¡åˆ¥"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ– AIO åˆ†æå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘ï¼Œé»˜èªä½¿ç”¨ config/settings.py
        """
        self.config = Config(config_path)
        self.logger = setup_logger(self.config.get('logging', {}))
        
        # åˆå§‹åŒ–å„å€‹è™•ç†å™¨
        self.gsc_handler = GSCHandler(self.config, self.logger)
        self.ads_handler = AdsHandler(self.config, self.logger)
        self.serp_handler = SERPHandler(self.config, self.logger)
        self.report_generator = ReportGenerator(self.config, self.logger)
        
        self.logger.info("AIO åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_configuration(self) -> bool:
        """
        é©—è­‰æ‰€æœ‰å¿…è¦çš„é…ç½®æ˜¯å¦æ­£ç¢ºè¨­ç½®
        
        Returns:
            bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        """
        self.logger.info("é–‹å§‹é©—è­‰é…ç½®...")
        
        required_configs = [
            ('gsc.credentials_file', self.config.get('gsc', {}).get('credentials_file')),
            ('ads.yaml_file', self.config.get('ads', {}).get('yaml_file')),
            ('serp.api_key', self.config.get('serp', {}).get('api_key')),
            ('analysis.site_url', self.config.get('analysis', {}).get('site_url')),
            ('analysis.customer_id', self.config.get('analysis', {}).get('customer_id'))
        ]
        
        for config_name, config_value in required_configs:
            if not config_value or config_value == "YOUR_API_KEY":
                self.logger.error(f"é…ç½®é …ç›® {config_name} æœªæ­£ç¢ºè¨­ç½®")
                return False
                
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_configs = [
            ('GSC credentials', self.config.get('gsc', {}).get('credentials_file')),
            ('Google Ads YAML', self.config.get('ads', {}).get('yaml_file'))
        ]
        
        for file_name, file_path in file_configs:
            if file_path and not os.path.exists(file_path):
                self.logger.error(f"{file_name} æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
        
        self.logger.info("é…ç½®é©—è­‰é€šé")
        return True
    
    async def extract_seed_keywords(self, 
                                   start_date: datetime, 
                                   end_date: datetime, 
                                   regex_pattern: str) -> pd.DataFrame:
        """
        å¾ Google Search Console æå–ç¨®å­é—œéµå­—
        
        Args:
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            regex_pattern: ç¯©é¸é—œéµå­—çš„æ­£å‰‡è¡¨é”å¼
            
        Returns:
            åŒ…å«ç¨®å­é—œéµå­—çš„ DataFrame
        """
        self.logger.info("é–‹å§‹å¾ GSC æå–ç¨®å­é—œéµå­—...")
        
        try:
            gsc_data = await self.gsc_handler.get_search_analytics_data(
                site_url=self.config.get('analysis', {}).get('site_url'),
                start_date=start_date.strftime('%Y-%m-%d'),
                end_date=end_date.strftime('%Y-%m-%d'),
                regex_pattern=regex_pattern
            )
            
            if gsc_data.empty:
                self.logger.warning("æœªå¾ GSC ç²å–åˆ°ä»»ä½•æ•¸æ“š")
                return pd.DataFrame()
            
            self.logger.info(f"æˆåŠŸæå– {len(gsc_data)} å€‹ç¨®å­é—œéµå­—")
            return gsc_data
            
        except Exception as e:
            self.logger.error(f"æå–ç¨®å­é—œéµå­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return pd.DataFrame()
    
    async def expand_keywords(self, seed_keywords: List[str]) -> pd.DataFrame:
        """
        ä½¿ç”¨ Google Ads API æ“´å±•é—œéµå­—
        
        Args:
            seed_keywords: ç¨®å­é—œéµå­—åˆ—è¡¨
            
        Returns:
            æ“´å±•å¾Œçš„é—œéµå­— DataFrame
        """
        self.logger.info("é–‹å§‹é€²è¡Œé—œéµå­—æ“´å±•...")
        
        if not seed_keywords:
            self.logger.warning("æ²’æœ‰ç¨®å­é—œéµå­—å¯ä¾›æ“´å±•")
            return pd.DataFrame()
        
        try:
            expanded_data = await self.ads_handler.generate_keyword_ideas(
                seed_keywords=seed_keywords,
                customer_id=self.config.get('analysis', {}).get('customer_id')
            )
            
            if expanded_data.empty:
                self.logger.warning("é—œéµå­—æ“´å±•æœªç”¢ç”Ÿä»»ä½•çµæœ")
                return pd.DataFrame()
            
            self.logger.info(f"æˆåŠŸæ“´å±•å‡º {len(expanded_data)} å€‹é—œéµå­—")
            return expanded_data
            
        except Exception as e:
            self.logger.error(f"é—œéµå­—æ“´å±•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return pd.DataFrame()
    
    async def validate_aio_triggers(self, keywords_df: pd.DataFrame) -> pd.DataFrame:
        """
        é©—è­‰é—œéµå­—æ˜¯å¦è§¸ç™¼ AIO
        
        Args:
            keywords_df: åŒ…å«é—œéµå­—çš„ DataFrame
            
        Returns:
            åŒ…å« AIO è§¸ç™¼é©—è­‰çµæœçš„ DataFrame
        """
        self.logger.info("é–‹å§‹é€²è¡Œ AIO è§¸ç™¼é©—è­‰...")
        
        if keywords_df.empty:
            self.logger.warning("æ²’æœ‰é—œéµå­—å¯ä¾›é©—è­‰")
            return keywords_df
        
        try:
            validated_data = await self.serp_handler.batch_validate_aio(
                keywords=keywords_df['keyword_idea'].tolist()
            )
            
            # å°‡é©—è­‰çµæœåˆä½µåˆ°åŸå§‹ DataFrame
            keywords_df['triggers_aio'] = keywords_df['keyword_idea'].map(validated_data)
            
            aio_count = keywords_df['triggers_aio'].sum()
            total_count = len(keywords_df)
            
            self.logger.info(f"AIO é©—è­‰å®Œæˆ: {aio_count}/{total_count} å€‹é—œéµå­—è§¸ç™¼ AIO")
            return keywords_df
            
        except Exception as e:
            self.logger.error(f"AIO é©—è­‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return keywords_df
    
    async def generate_comprehensive_report(self, 
                                          final_df: pd.DataFrame, 
                                          gsc_df: pd.DataFrame) -> str:
        """
        ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š
        
        Args:
            final_df: æœ€çµ‚åˆ†æçµæœ DataFrame
            gsc_df: åŸå§‹ GSC æ•¸æ“š DataFrame
            
        Returns:
            å ±å‘Šæ–‡ä»¶è·¯å¾‘
        """
        self.logger.info("é–‹å§‹ç”Ÿæˆç¶œåˆå ±å‘Š...")
        
        try:
            report_path = await self.report_generator.generate_detailed_report(
                analysis_data=final_df,
                gsc_data=gsc_df,
                output_dir=self.config.get('output', {}).get('directory', 'output')
            )
            
            self.logger.info(f"å ±å‘Šå·²ç”Ÿæˆ: {report_path}")
            return report_path
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return ""
    
    async def run_full_analysis(self, 
                               days_back: int = 90,
                               regex_pattern: str = r'^(what|how|why|when|where|who|which|ä»€éº¼|å¦‚ä½•|ç‚ºä½•|å“ªè£¡|èª°æ˜¯)\b') -> Dict[str, any]:
        """
        åŸ·è¡Œå®Œæ•´çš„ AIO æ½›åŠ›åˆ†ææµç¨‹
        
        Args:
            days_back: å‘å‰è¿½æº¯çš„å¤©æ•¸
            regex_pattern: ç¯©é¸é—œéµå­—çš„æ­£å‰‡è¡¨é”å¼
            
        Returns:
            åˆ†æçµæœæ‘˜è¦
        """
        if not self.validate_configuration():
            raise ValueError("é…ç½®é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥é…ç½®æ–‡ä»¶")
        
        self.logger.info("=== é–‹å§‹åŸ·è¡Œå®Œæ•´ AIO æ½›åŠ›åˆ†æ ===")
        
        # è¨­å®šåˆ†ææ™‚é–“ç¯„åœ
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        self.logger.info(f"åˆ†ææ™‚é–“ç¯„åœ: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
        
        # ç¬¬ä¸€æ­¥ï¼šæå–ç¨®å­é—œéµå­—
        gsc_data = await self.extract_seed_keywords(start_date, end_date, regex_pattern)
        if gsc_data.empty:
            return {"status": "failed", "message": "ç„¡æ³•ç²å–ç¨®å­é—œéµå­—"}
        
        # ç¬¬äºŒæ­¥ï¼šæ“´å±•é—œéµå­—
        seed_keywords = gsc_data['query'].tolist()
        expanded_data = await self.expand_keywords(seed_keywords)
        if expanded_data.empty:
            return {"status": "failed", "message": "é—œéµå­—æ“´å±•å¤±æ•—"}
        
        # ç¬¬ä¸‰æ­¥ï¼šé©—è­‰ AIO è§¸ç™¼
        validated_data = await self.validate_aio_triggers(expanded_data)
        
        # ç¬¬å››æ­¥ï¼šç”Ÿæˆå ±å‘Š
        report_path = await self.generate_comprehensive_report(validated_data, gsc_data)
        
        # è¨ˆç®—åˆ†æçµæœæ‘˜è¦
        total_keywords = len(validated_data)
        aio_keywords = validated_data['triggers_aio'].sum() if 'triggers_aio' in validated_data.columns else 0
        aio_percentage = (aio_keywords / total_keywords * 100) if total_keywords > 0 else 0
        
        summary = {
            "status": "completed",
            "analysis_period": {
                "start": start_date.strftime('%Y-%m-%d'),
                "end": end_date.strftime('%Y-%m-%d')
            },
            "seed_keywords_count": len(gsc_data),
            "expanded_keywords_count": total_keywords,
            "aio_triggers_count": aio_keywords,
            "aio_percentage": round(aio_percentage, 2),
            "report_path": report_path
        }
        
        self.logger.info("=== AIO æ½›åŠ›åˆ†æå®Œæˆ ===")
        self.logger.info(f"åˆ†ææ‘˜è¦: {summary}")
        
        return summary


async def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    try:
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = AIOAnalyzer()
        
        # åŸ·è¡Œå®Œæ•´åˆ†æ
        results = await analyzer.run_full_analysis(
            days_back=90,
            regex_pattern=r'^(what|how|why|when|where|who|which|ä»€éº¼|å¦‚ä½•|ç‚ºä½•|å“ªè£¡|èª°æ˜¯)\b'
        )
        
        # è¼¸å‡ºçµæœ
        print("\n" + "="*60)
        print("AIO æ½›åŠ›åˆ†æçµæœæ‘˜è¦")
        print("="*60)
        
        if results["status"] == "completed":
            print(f"âœ… åˆ†æç‹€æ…‹: æˆåŠŸå®Œæˆ")
            print(f"ğŸ“… åˆ†ææœŸé–“: {results['analysis_period']['start']} è‡³ {results['analysis_period']['end']}")
            print(f"ğŸŒ± ç¨®å­é—œéµå­—æ•¸é‡: {results['seed_keywords_count']}")
            print(f"ğŸ” æ“´å±•é—œéµå­—æ•¸é‡: {results['expanded_keywords_count']}")
            print(f"ğŸ¤– è§¸ç™¼ AIO é—œéµå­—æ•¸é‡: {results['aio_triggers_count']}")
            print(f"ğŸ“Š AIO è§¸ç™¼ç‡: {results['aio_percentage']}%")
            print(f"ğŸ“„ å ±å‘Šä½ç½®: {results['report_path']}")
        else:
            print(f"âŒ åˆ†æå¤±æ•—: {results['message']}")
        
        print("="*60)
        
    except Exception as e:
        print(f"åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        logging.error(f"ä¸»ç¨‹åºåŸ·è¡ŒéŒ¯èª¤: {e}", exc_info=True)


if __name__ == '__main__':
    asyncio.run(main())

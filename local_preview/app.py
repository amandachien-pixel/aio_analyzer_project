#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIO åˆ†æå™¨æœ¬åœ°é è¦½æ‡‰ç”¨
====================

è¼•é‡ç´š Flask æ‡‰ç”¨ï¼Œæä¾›ç°¡æ˜æ˜“ç”¨çš„ UI ä¾†é è¦½ AIO åˆ†æåŠŸèƒ½ã€‚
ä½¿ç”¨ MCP (Model Context Protocol) é‚è¼¯é€²è¡Œæ¨¡çµ„åŒ–è™•ç†ã€‚
"""

import os
import sys
import asyncio
import json
import threading
from datetime import datetime, timedelta
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_file
import pandas as pd
import numpy as np

# æ·»åŠ  src ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from utils.gsc_handler import GSCHandler
from utils.ads_handler import AdsHandler
from utils.serp_handler import SERPHandler
from utils.report_generator import ReportGenerator
from utils.logger import setup_logger

# Flask æ‡‰ç”¨è¨­å®š
app = Flask(__name__)
app.secret_key = 'aio-analyzer-preview-key'

# å…¨å±€è®Šæ•¸
analysis_status = {
    'current_step': 'idle',
    'progress': 0,
    'message': 'ç­‰å¾…é–‹å§‹åˆ†æ',
    'results': {}
}

# MCP é‚è¼¯é¡åˆ¥
class MCPAnalysisHandler:
    """
    ä½¿ç”¨ MCP (Model Context Protocol) é‚è¼¯çš„åˆ†æè™•ç†å™¨
    å°‡è¤‡é›œçš„åˆ†ææµç¨‹æ¨¡çµ„åŒ–ç‚ºæ¸…æ™°çš„æ­¥é©Ÿ
    """
    
    def __init__(self):
        self.logger = setup_logger({'level': 'INFO'})
        self.current_project = None
        self.analysis_data = {}
    
    async def execute_analysis_pipeline(self, params):
        """åŸ·è¡Œå®Œæ•´çš„åˆ†æç®¡é“"""
        global analysis_status
        
        try:
            # æ­¥é©Ÿ 1: åˆå§‹åŒ–
            analysis_status.update({
                'current_step': 'initializing',
                'progress': 10,
                'message': 'æ­£åœ¨åˆå§‹åŒ–åˆ†æç’°å¢ƒ...'
            })
            
            # æº–å‚™é…ç½®
            config = self._prepare_config(params)
            
            # æ­¥é©Ÿ 2: GSC æ•¸æ“šæ“·å– (M1)
            analysis_status.update({
                'current_step': 'gsc_extraction',
                'progress': 25,
                'message': 'æ­£åœ¨å¾ Google Search Console æ“·å–ç¨®å­é—œéµå­—...'
            })
            
            gsc_data = await self._execute_gsc_extraction(config, params)
            
            # æ­¥é©Ÿ 3: é—œéµå­—æ“´å±• (M2)
            analysis_status.update({
                'current_step': 'keyword_expansion',
                'progress': 50,
                'message': 'æ­£åœ¨ä½¿ç”¨ Google Ads API æ“´å±•é—œéµå­—...'
            })
            
            expanded_data = await self._execute_keyword_expansion(config, gsc_data, params)
            
            # æ­¥é©Ÿ 4: AIO é©—è­‰ (M3)
            analysis_status.update({
                'current_step': 'aio_validation',
                'progress': 75,
                'message': 'æ­£åœ¨é©—è­‰é—œéµå­—æ˜¯å¦è§¸ç™¼ AI Overview...'
            })
            
            validated_data = await self._execute_aio_validation(config, expanded_data)
            
            # æ­¥é©Ÿ 5: å ±å‘Šç”Ÿæˆ (M4)
            analysis_status.update({
                'current_step': 'report_generation',
                'progress': 90,
                'message': 'æ­£åœ¨ç”Ÿæˆåˆ†æå ±å‘Š...'
            })
            
            report_path = await self._execute_report_generation(validated_data, gsc_data)
            
            # å®Œæˆ
            analysis_status.update({
                'current_step': 'completed',
                'progress': 100,
                'message': 'åˆ†æå®Œæˆï¼',
                'results': {
                    'total_keywords': len(validated_data),
                    'aio_keywords': validated_data['triggers_aio'].sum() if 'triggers_aio' in validated_data.columns else 0,
                    'report_path': report_path,
                    'completion_time': datetime.now().isoformat()
                }
            })
            
            return analysis_status['results']
            
        except Exception as e:
            analysis_status.update({
                'current_step': 'error',
                'progress': 0,
                'message': f'åˆ†æå¤±æ•—: {str(e)}',
                'error': str(e)
            })
            self.logger.error(f"åˆ†æç®¡é“åŸ·è¡Œå¤±æ•—: {e}")
            raise
    
    def _prepare_config(self, params):
        """æº–å‚™åˆ†æé…ç½®"""
        return {
            'gsc': {
                'credentials_file': str(Path(__file__).parent.parent / 'config' / 'credentials.json'),
                'token_file': str(Path(__file__).parent.parent / 'config' / 'token.json'),
                'scopes': ['https://www.googleapis.com/auth/webmasters.readonly']
            },
            'ads': {
                'yaml_file': str(Path(__file__).parent.parent / 'config' / 'google-ads.yaml'),
                'language_code': 'gid/1001',
                'geo_target_code': 'gid/1013274',
                'keyword_limit': 20
            },
            'serp': {
                'provider': os.getenv('SERP_API_PROVIDER', 'serper'),
                'api_key': os.getenv('SERP_API_KEY', 'demo-key'),
                'endpoint': os.getenv('SERP_API_ENDPOINT', 'https://google.serper.dev/search'),
                'country': 'tw',
                'language': 'zh-tw',
                'concurrent_requests': 3,
                'rate_limit': 1.0
            },
            'performance': {
                'timeout': 30,
                'retry_attempts': 2,
                'retry_delay': 1
            }
        }
    
    async def _execute_gsc_extraction(self, config, params):
        """åŸ·è¡Œ GSC æ•¸æ“šæ“·å–"""
        # æ¨¡æ“¬æ•¸æ“šï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æœƒé€£æ¥çœŸå¯¦ GSC APIï¼‰
        if not os.path.exists(config['gsc']['credentials_file']):
            # ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š
            demo_data = {
                'query': [
                    'what is ai overview',
                    'how to optimize for ai overview',
                    'ai overview seo strategy',
                    'ä»€éº¼æ˜¯ AI Overview',
                    'å¦‚ä½•å„ªåŒ– AI Overview'
                ],
                'clicks': [120, 85, 67, 45, 32],
                'impressions': [1500, 920, 780, 560, 410],
                'ctr': [0.08, 0.092, 0.086, 0.08, 0.078],
                'position': [3.2, 4.1, 5.2, 6.8, 7.5]
            }
            return pd.DataFrame(demo_data)
        else:
            # ä½¿ç”¨çœŸå¯¦ GSC API
            gsc_handler = GSCHandler(config, self.logger)
            return await gsc_handler.get_search_analytics_data(
                site_url=params.get('site_url', 'sc-domain:example.com'),
                start_date=params.get('start_date'),
                end_date=params.get('end_date'),
                regex_pattern=params.get('regex_pattern', r'^(what|how|why)\b')
            )
    
    async def _execute_keyword_expansion(self, config, gsc_data, params):
        """åŸ·è¡Œé—œéµå­—æ“´å±•"""
        if gsc_data.empty:
            return pd.DataFrame()
        
        # æ¨¡æ“¬æ“´å±•æ•¸æ“š
        seed_keywords = gsc_data['query'].tolist()
        expanded_keywords = []
        
        for keyword in seed_keywords:
            # ç‚ºæ¯å€‹ç¨®å­é—œéµå­—ç”Ÿæˆç›¸é—œå»ºè­°
            variants = [
                f"{keyword} guide",
                f"{keyword} tutorial", 
                f"{keyword} tips",
                f"best {keyword}",
                f"{keyword} 2024"
            ]
            
            for variant in variants:
                expanded_keywords.append({
                    'keyword_idea': variant,
                    'search_volume': np.random.randint(100, 5000),
                    'competition_level': np.random.choice(['LOW', 'MEDIUM', 'HIGH']),
                    'competition_index': np.random.randint(10, 90)
                })
        
        return pd.DataFrame(expanded_keywords)
    
    async def _execute_aio_validation(self, config, expanded_data):
        """åŸ·è¡Œ AIO é©—è­‰"""
        if expanded_data.empty:
            return expanded_data
        
        # æª¢æŸ¥ SERP API é…ç½®
        if config['serp']['api_key'] == 'demo-key':
            # æ¨¡æ“¬ AIO é©—è­‰çµæœ
            expanded_data['triggers_aio'] = np.random.choice([True, False], 
                                                           size=len(expanded_data), 
                                                           p=[0.3, 0.7])  # 30% è§¸ç™¼ç‡
        else:
            # ä½¿ç”¨çœŸå¯¦ SERP API
            serp_handler = SERPHandler(config, self.logger)
            keywords = expanded_data['keyword_idea'].tolist()
            validation_results = await serp_handler.batch_validate_aio(keywords[:10])  # é™åˆ¶æ•¸é‡
            expanded_data['triggers_aio'] = expanded_data['keyword_idea'].map(validation_results)
        
        return expanded_data
    
    async def _execute_report_generation(self, validated_data, gsc_data):
        """åŸ·è¡Œå ±å‘Šç”Ÿæˆ"""
        output_dir = Path(__file__).parent / 'reports'
        output_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆå ±å‘Š
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = output_dir / f'aio_analysis_{timestamp}.csv'
        
        # æº–å‚™å ±å‘Šæ•¸æ“š
        if not validated_data.empty:
            report_data = validated_data.copy()
            report_data['è§¸ç™¼AIO'] = report_data['triggers_aio'].apply(lambda x: 'Y' if x else 'N')
            report_data.to_csv(report_path, index=False, encoding='utf-8-sig')
        
        return str(report_path)


# MCP è™•ç†å™¨å¯¦ä¾‹
mcp_handler = MCPAnalysisHandler()


@app.route('/')
def index():
    """ä¸»é é¢"""
    return render_template('index.html')


@app.route('/api/start_analysis', methods=['POST'])
def start_analysis():
    """é–‹å§‹åˆ†æ"""
    try:
        params = request.json
        
        # åœ¨èƒŒæ™¯åŸ·è¡Œåˆ†æ
        def run_analysis():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(mcp_handler.execute_analysis_pipeline(params))
            finally:
                loop.close()
        
        # é‡ç½®ç‹€æ…‹
        global analysis_status
        analysis_status = {
            'current_step': 'starting',
            'progress': 0,
            'message': 'æ­£åœ¨å•Ÿå‹•åˆ†æ...',
            'results': {}
        }
        
        # åœ¨æ–°åŸ·è¡Œç·’ä¸­åŸ·è¡Œåˆ†æ
        thread = threading.Thread(target=run_analysis)
        thread.daemon = True
        thread.start()
        
        return jsonify({'status': 'started', 'message': 'åˆ†æå·²é–‹å§‹'})
        
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/analysis_status')
def get_analysis_status():
    """ç²å–åˆ†æç‹€æ…‹"""
    return jsonify(analysis_status)


@app.route('/api/demo_data')
def get_demo_data():
    """ç²å–æ¼”ç¤ºæ•¸æ“š"""
    demo_results = {
        'gsc_data': {
            'total_queries': 5,
            'total_clicks': 349,
            'total_impressions': 4170,
            'avg_ctr': 0.084
        },
        'expanded_keywords': {
            'total_keywords': 25,
            'avg_search_volume': 1250,
            'competition_distribution': {
                'LOW': 8, 'MEDIUM': 10, 'HIGH': 7
            }
        },
        'aio_validation': {
            'total_validated': 25,
            'aio_triggers': 8,
            'aio_percentage': 32.0
        }
    }
    return jsonify(demo_results)


@app.route('/download_report/<filename>')
def download_report(filename):
    """ä¸‹è¼‰å ±å‘Š"""
    try:
        report_path = Path(__file__).parent / 'reports' / filename
        if report_path.exists():
            return send_file(report_path, as_attachment=True)
        else:
            return jsonify({'error': 'å ±å‘Šæ–‡ä»¶ä¸å­˜åœ¨'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # ç¢ºä¿å¿…è¦çš„ç›®éŒ„å­˜åœ¨
    os.makedirs('reports', exist_ok=True)
    
    print("ğŸš€ AIO åˆ†æå™¨æœ¬åœ°é è¦½å•Ÿå‹•ä¸­...")
    print("ğŸ“± è«‹åœ¨ç€è¦½å™¨ä¸­è¨ªå•: http://localhost:5001")
    print("ğŸ’¡ é€™æ˜¯é è¦½ç‰ˆæœ¬ï¼ŒæŸäº›åŠŸèƒ½ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
    print("ğŸ”§ å®Œæ•´åŠŸèƒ½éœ€è¦é…ç½® API æ†‘è­‰")
    
    # å•Ÿå‹• Flask æ‡‰ç”¨
    app.run(debug=True, host='0.0.0.0', port=5001)
